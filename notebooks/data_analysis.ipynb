{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "- **Train, Dev, and Test Splits**: Each line in a document representing a data sample (a sentence pair containing target event mentions).\n",
    "\n",
    "- Format: Each line includes (separated by tabs):\n",
    "\n",
    "    - Unique ID of event mention1 from sentence1(e.g. 01_04_35#2_3_3) \n",
    "    - Unique ID of event mention2 from sentence2(e.g. 01_04_35#2_3_3)  \n",
    "    - Sentence 1  \n",
    "    - Start token index of event1 trigger word \n",
    "    - End token index of event1 trigger word(inclusive) \n",
    "    - Start token index of event1 participant phrase 1 \n",
    "    - End token index of event1 participant phrase 1(inclusive) \n",
    "    - Start token index of event1 participant phrase 2 \n",
    "    - End token index of event1 participant phrase 2(inclusive) \n",
    "    - Start token index of event1 time End token index of event1 time (inclusive) \n",
    "    - Start token index of event1 location End token index of event1 location (inclusive) \n",
    "    - Sentence 2 \n",
    "    - Start token index of event2 trigger word \n",
    "    - End token index of event2 trigger word (inclusive) \n",
    "    - Start token index of event2 participant phrase 1\n",
    "    - End token index of event2 participant phrase 1 (inclusive) \n",
    "    - Start token index of event2 participant phrase 2 \n",
    "    - End token index of event2 participant phrase 2 (inclusive) \n",
    "    - Start token index of event2 time End token index of event2 time (inclusive) \n",
    "    - Start token index of event2 location \n",
    "    - End token index of event2 location (inclusive) \n",
    "    - label: A binary label indicating whether the events are coreferent (1) or not (0).\n",
    "\n",
    "NOTE: index -1 means this information is not provided in data. You can choose to leave it be -1 or you can extract the participants, time and location of the event mentions for extra credit. Event trigger word is provided in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_set = pd.read_csv(\"../data/event_pairs.train\", sep='\\t', on_bad_lines='skip')\n",
    "dev_set = pd.read_csv(\"../data/event_pairs.dev\", sep='\\t', on_bad_lines='skip')\n",
    "test_set = pd.read_csv(\"../data/event_pairs.test\", sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "col_names = [\n",
    "    \"sentence1\",\n",
    "    \"e1_trigger_start\",\n",
    "    \"e1_trigger_end\",\n",
    "    \"e1_participant1_start\",\n",
    "    \"e1_participant1_end\",\n",
    "    \"e1_participant2_start\",\n",
    "    \"e1_participant2_end\",\n",
    "    \"e1_time_start\",\n",
    "    \"e1_time_end\",\n",
    "    \"e1_loc_start\",\n",
    "    \"e1_loc_end\",\n",
    "    \"sentence2\",\n",
    "    \"e2_trigger_start\",\n",
    "    \"e2_trigger_end\",\n",
    "    \"e2_participant1_start\",\n",
    "    \"e2_participant1_end\",\n",
    "    \"e2_participant2_start\",\n",
    "    \"e2_participant2_end\",\n",
    "    \"e2_time_start\",\n",
    "    \"e2_time_end\",\n",
    "    \"e2_loc_start\",\n",
    "    \"e2_loc_end\",\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "train_set.columns = col_names\n",
    "dev_set.columns = col_names\n",
    "test_set.columns = ['event_id_1', 'event_id_2'] + col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    202078\n",
      "1.0     19252\n",
      "Name: count, dtype: int64\n",
      "Number of unique setence 1 in train set: 6279\n",
      "Number of unique setence 2 in train set: 6001\n",
      "Number of total number of unique sentences in train set: 7011\n"
     ]
    }
   ],
   "source": [
    "print(train_set.label.value_counts())\n",
    "print(f\"Number of unique setence 1 in train set: {len(train_set.sentence1.unique())}\")\n",
    "print(f\"Number of unique setence 2 in train set: {len(train_set.sentence2.unique())}\")\n",
    "\n",
    "set_1 = set(train_set.sentence1.unique())\n",
    "set_2 = set(train_set.sentence2.unique())\n",
    "set_1.update(set_2)\n",
    "print(f\"Number of total number of unique sentences in train set: {len(set_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of e1_participant1_start provided in train set: 0\n",
      "Number of e1_participant1_end provided in train set: 0\n",
      "Number of e1_participant2_start provided in train set: 0\n",
      "Number of e1_participant2_end provided in train set: 0\n",
      "Number of e1_time_start provided in train set: 0\n",
      "Number of e1_time_end provided in train set: 0\n",
      "Number of e1_loc_start provided in train set: 0\n",
      "Number of e1_loc_end provided in train set: 0\n",
      "Number of e2_participant1_start provided in train set: 458\n",
      "Number of e2_participant1_end provided in train set: 458\n",
      "Number of e2_participant2_start provided in train set: 458\n",
      "Number of e2_participant2_end provided in train set: 458\n",
      "Number of e2_time_start provided in train set: 458\n",
      "Number of e2_time_end provided in train set: 458\n",
      "Number of e2_loc_start provided in train set: 458\n",
      "Number of e2_loc_end provided in train set: 458\n"
     ]
    }
   ],
   "source": [
    "# check the number of event info provided in train set\n",
    "event_info_names = [\n",
    "    \"e1_participant1_start\",\n",
    "    \"e1_participant1_end\",\n",
    "    \"e1_participant2_start\",\n",
    "    \"e1_participant2_end\",\n",
    "    \"e1_time_start\",\n",
    "    \"e1_time_end\",\n",
    "    \"e1_loc_start\",\n",
    "    \"e1_loc_end\",\n",
    "    \"e2_participant1_start\",\n",
    "    \"e2_participant1_end\",\n",
    "    \"e2_participant2_start\",\n",
    "    \"e2_participant2_end\",\n",
    "    \"e2_time_start\",\n",
    "    \"e2_time_end\",\n",
    "    \"e2_loc_start\",\n",
    "    \"e2_loc_end\",\n",
    "    \n",
    "] \n",
    "\n",
    "for event_info_name in event_info_names:\n",
    "    print(f\"Number of {event_info_name} provided in train set: {len(train_set[train_set[event_info_name] != -1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
